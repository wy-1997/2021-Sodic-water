{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import lightgbm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "from borax.calendars.lunardate import LunarDate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yang2nong(date):\n",
    "    \n",
    "    year = int(date[:4])\n",
    "    month = int(date[4:6])\n",
    "    day = int(date[6:8])\n",
    "    \n",
    "    nong =  LunarDate.from_solar_date(year, month, day)\n",
    "    \n",
    "    res = nong.__format__('%y-%m-%d')\n",
    "    return res\n",
    "\n",
    "def create_features(dataframe):\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['month'] = dataframe.date.dt.month\n",
    "    dataframe['day_of_month'] = dataframe.date.dt.day\n",
    "    dataframe['day_of_year'] = dataframe.date.dt.dayofyear\n",
    "    dataframe['week_of_year'] = dataframe.date.dt.weekofyear\n",
    "    dataframe['day_of_week'] = dataframe.date.dt.dayofweek + 1\n",
    "    dataframe['year'] = dataframe.date.dt.year\n",
    "    dataframe['is_wknd'] = dataframe.date.dt.weekday // 4\n",
    "    dataframe['is_month_start'] = dataframe.date.dt.is_month_start.astype(int)\n",
    "    dataframe['is_month_end'] = dataframe.date.dt.is_month_end.astype(int)\n",
    "    dataframe['quarter'] = dataframe.date.dt.quarter\n",
    "    dataframe['week_block_num'] = [int(x) for x in np.floor((dataframe.date - pd.to_datetime('2017-12-31')).dt.days / 7) + 1]\n",
    "    dataframe['quarter_block_num'] = (dataframe['year'] - 2018) * 4 + dataframe['quarter']\n",
    "    dataframe['week_of_month'] = dataframe['week_of_year'].values // 4.35\n",
    "    \n",
    "    #新增星期几时间变量\n",
    "    dataframe['is_Mon'] = np.where(dataframe['day_of_week'] == 1, 1, 0)                                                                                       \n",
    "    dataframe['is_Tue'] = np.where(dataframe['day_of_week'] == 2, 1, 0)                                                                                         \n",
    "    dataframe['is_Wed'] = np.where(dataframe['day_of_week'] == 3, 1, 0)                                                                                         \n",
    "    dataframe['is_Thu'] = np.where(dataframe['day_of_week'] == 4, 1, 0)                                                                                         \n",
    "    dataframe['is_Fri'] = np.where(dataframe['day_of_week'] == 5, 1, 0)                                                                                         \n",
    "    dataframe['is_Sat'] = np.where(dataframe['day_of_week'] == 6, 1, 0)                                                                                         \n",
    "    dataframe['is_Sun'] = np.where(dataframe['day_of_week'] == 7, 1, 0)\n",
    "    #新增每月上中下旬\n",
    "    dataframe['day_of_month_10days']=np.where((dataframe['day_of_month']<=10) == 1, 1, 0)\n",
    "    dataframe['day_of_month_20days']=np.where(((dataframe['day_of_month']>10)&(dataframe['day_of_month']<=20)) == 1, 1, 0)\n",
    "    dataframe['day_of_month_30days']=np.where((dataframe['day_of_month']>20) == 1, 1, 0)\n",
    "    dataframe['day_of_year_>180days']=np.where((dataframe['day_of_year']>180) == 1, 1, 0)\n",
    "    dataframe['day_of_year_<180days']=np.where((dataframe['day_of_year']<=180) == 1, 1, 0)\n",
    "\n",
    "\n",
    "    dataframe['abs_month']=dataframe['day_of_month'].apply(lambda x: abs(x-16)+1)\n",
    "    \n",
    "    \n",
    "    dataframe['CH_month'] = dataframe.China_date.dt.month  #农历月\n",
    "    dataframe['CH_day_of_month'] = dataframe.China_date.dt.day #农历日\n",
    "    dataframe['CH_day_of_year'] = dataframe.China_date.dt.dayofyear #农历的哪一天\n",
    "    dataframe['abs_year']=dataframe['CH_day_of_year'].apply(lambda x: abs(x-182)+1)    \n",
    "    \n",
    "    #dataframe.drop(['date','post_id'],axis=1,inplace=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\28947\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
     ]
    }
   ],
   "source": [
    "#数据读取与wkd表连接\n",
    "train_df=pd.read_csv('../data/train.csv')\n",
    "train_df.columns=['date','A','B']\n",
    "train_df.date=pd.to_datetime(train_df.date)\n",
    "test_day=pd.read_csv('../data/test.csv')#按天计算\n",
    "#wkd=pd.read_csv('../data/wkd_v1.csv')    #不使用用外部数据\n",
    "#wkd=wkd.rename(columns={'ORIG_DT':'date'})\n",
    "#wkd.date=pd.to_datetime(wkd.date)\n",
    "#train_df=train_df.merge(wkd,on='date',how='left')\n",
    "test_day.columns = ['date','A','B']\n",
    "test_day.date = pd.to_datetime(test_day.date)\n",
    "#test_day = test_day.merge(wkd,on='date',how='left')\n",
    "\n",
    "#进行农历转换\n",
    "test_day['date1'] = test_day.date.dt.strftime('%Y%m%d')\n",
    "test_day['China_date']=test_day['date1'].apply(lambda x: yang2nong(x))\n",
    "#农历2月不同与公历2月，\n",
    "#因此采用前向填充方式以构建pandas时间戳，难题在与20年存在的闰四月现象    \n",
    "test_day.replace(['2018-2-29','2018-2-30','2019-2-29',\n",
    "            '2020-2-29','2020-2-30'],np.nan,inplace=True)\n",
    "    \n",
    "test_day['China_date']=test_day['China_date'].fillna(method='ffill')\n",
    "test_day['China_date'] = pd.to_datetime(test_day['China_date'])\n",
    "\n",
    "#进行农历转换\n",
    "train_df['date1'] = train_df.date.dt.strftime('%Y%m%d')\n",
    "train_df['China_date']=train_df['date1'].apply(lambda x: yang2nong(x))\n",
    "#农历2月不同与公历2月，\n",
    "#因此采用前向填充方式以构建pandas时间戳，难题在与20年存在的闰四月现象    \n",
    "train_df.replace(['2018-2-29','2018-2-30','2019-2-29',\n",
    "            '2020-2-29','2020-2-30'],np.nan,inplace=True)\n",
    "    \n",
    "train_df['China_date']=train_df['China_date'].fillna(method='ffill')\n",
    "train_df['China_date'] = pd.to_datetime(train_df['China_date'])\n",
    "\n",
    "train_day_df_A = train_df[['date','A','China_date']]\n",
    "train_day_df_B = train_df[['date','B','China_date']]\n",
    "\n",
    "train_day_df_A=create_features(train_day_df_A)\n",
    "train_day_df_B=create_features(train_day_df_B)\n",
    "\n",
    "train_day_df_A['A']=train_day_df_A['A']\n",
    "train_day_df_B['B']=train_day_df_B['B']\n",
    "\n",
    "\n",
    "test_day_df_A = test_day[['date','A','China_date']]\n",
    "test_day_df_B = test_day[['date','B','China_date']]\n",
    "test_day_df_A=create_features(test_day_df_A)\n",
    "test_day_df_B=create_features(test_day_df_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_cv(train_x, train_y, test_x):\n",
    "    predictors = list(train_x.columns)\n",
    "    train_x = train_x.values\n",
    "    test_x = test_x.values\n",
    "    \n",
    "    \n",
    "    folds = 10\n",
    "    seed = 2021\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    train = np.zeros((train_x.shape[0]))\n",
    "    test = np.zeros((test_x.shape[0]))\n",
    "    test_pre = np.zeros((folds, test_x.shape[0]))\n",
    "    test_pre_all = np.zeros((folds, test_x.shape[0]))\n",
    "    cv_scores = []\n",
    "    tpr_scores = []\n",
    "    cv_rounds = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        tr_x = train_x[train_index]\n",
    "        tr_y = train_y[train_index]\n",
    "        te_x = train_x[test_index]\n",
    "        te_y = train_y[test_index]\n",
    "        train_matrix = lightgbm.Dataset(tr_x, label=tr_y)\n",
    "        test_matrix = lightgbm.Dataset(te_x, label=te_y)\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metrics':'mean_squared_error',\n",
    "            'num_leaves': 2 ** 5-1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'learning_rate': 0.05,\n",
    "            'lambda_l1': 0.01,                                                                                                                    \n",
    "            'lambda_l2': 0.01,\n",
    "            'seed': 2021,\n",
    "            \n",
    "            \n",
    "            'nthread': 4,\n",
    "            'verbose': -1,\n",
    "            \n",
    "            \n",
    "        }\n",
    "        num_round = 10000\n",
    "        early_stopping_rounds = 200    \n",
    "        \n",
    "        if test_matrix:\n",
    "            model = lightgbm.train(params, train_matrix, num_round, valid_sets=test_matrix, verbose_eval=200,\n",
    "                              #feval=tpr_eval_score,\n",
    "                              early_stopping_rounds=early_stopping_rounds\n",
    "                              )\n",
    "            #print(\"\\n\".join((\"%s: %.2f\" % x) for x in list(sorted(zip(predictors, model.feature_importance(\"gain\")),\n",
    "                        #key=lambda x: x[1],reverse=True))[:30]))\n",
    "            importance_list=[ x[0] for x in list(sorted(zip(predictors, model.feature_importance(\"gain\")),\n",
    "                        key=lambda x: x[1],reverse=True))]\n",
    "            \n",
    "            pre = model.predict(te_x, num_iteration=model.best_iteration)#\n",
    "            pred = model.predict(test_x, num_iteration=model.best_iteration)#\n",
    "            train[test_index] = pre\n",
    "            test_pre[i, :] = pred\n",
    "            cv_scores.append(mean_squared_error (te_y, pre))\n",
    "            cv_rounds.append(model.best_iteration)\n",
    "            test_pre_all[i, :] = pred\n",
    "        #\n",
    "        print(\"cv_score is:\", cv_scores)\n",
    "    use_mean=True\n",
    "    if use_mean:\n",
    "        test[:] = test_pre.mean(axis=0)\n",
    "    else:\n",
    "        pass\n",
    "    #\n",
    "    print(\"val_mean:\" , np.mean(cv_scores))\n",
    "    print(\"val_std:\", np.std(cv_scores))\n",
    "    return model, train, test, test_pre_all, np.mean(cv_scores),importance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 8) (550,) (151, 8)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.96912e+08\n",
      "[400]\tvalid_0's l2: 1.47627e+08\n",
      "[600]\tvalid_0's l2: 1.28195e+08\n",
      "[800]\tvalid_0's l2: 1.20884e+08\n",
      "[1000]\tvalid_0's l2: 1.15834e+08\n",
      "[1200]\tvalid_0's l2: 1.13484e+08\n",
      "[1400]\tvalid_0's l2: 1.11905e+08\n",
      "[1600]\tvalid_0's l2: 1.11699e+08\n",
      "[1800]\tvalid_0's l2: 1.11296e+08\n",
      "Early stopping, best iteration is:\n",
      "[1721]\tvalid_0's l2: 1.10941e+08\n",
      "cv_score is: [110940659.75047639]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.23176e+08\n",
      "[400]\tvalid_0's l2: 1.08842e+08\n",
      "[600]\tvalid_0's l2: 1.06989e+08\n",
      "[800]\tvalid_0's l2: 1.07472e+08\n",
      "Early stopping, best iteration is:\n",
      "[681]\tvalid_0's l2: 1.06513e+08\n",
      "cv_score is: [110940659.75047639, 106513195.56387173]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.57461e+08\n",
      "[400]\tvalid_0's l2: 1.4825e+08\n",
      "[600]\tvalid_0's l2: 1.45406e+08\n",
      "[800]\tvalid_0's l2: 1.41722e+08\n",
      "[1000]\tvalid_0's l2: 1.40838e+08\n",
      "[1200]\tvalid_0's l2: 1.39804e+08\n",
      "[1400]\tvalid_0's l2: 1.38605e+08\n",
      "Early stopping, best iteration is:\n",
      "[1365]\tvalid_0's l2: 1.38052e+08\n",
      "cv_score is: [110940659.75047639, 106513195.56387173, 138052331.11609027]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.46157e+08\n",
      "[400]\tvalid_0's l2: 1.28394e+08\n",
      "[600]\tvalid_0's l2: 1.1953e+08\n",
      "[800]\tvalid_0's l2: 1.14559e+08\n",
      "[1000]\tvalid_0's l2: 1.11786e+08\n",
      "[1200]\tvalid_0's l2: 1.10765e+08\n",
      "[1400]\tvalid_0's l2: 1.10534e+08\n",
      "[1600]\tvalid_0's l2: 1.10332e+08\n",
      "Early stopping, best iteration is:\n",
      "[1528]\tvalid_0's l2: 1.10078e+08\n",
      "cv_score is: [110940659.75047639, 106513195.56387173, 138052331.11609027, 110078380.21866015]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.47277e+08\n",
      "[400]\tvalid_0's l2: 1.46047e+08\n",
      "Early stopping, best iteration is:\n",
      "[380]\tvalid_0's l2: 1.45124e+08\n",
      "cv_score is: [110940659.75047639, 106513195.56387173, 138052331.11609027, 110078380.21866015, 145123529.74018514]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.39153e+08\n",
      "[400]\tvalid_0's l2: 1.37557e+08\n",
      "Early stopping, best iteration is:\n",
      "[346]\tvalid_0's l2: 1.37323e+08\n",
      "cv_score is: [110940659.75047639, 106513195.56387173, 138052331.11609027, 110078380.21866015, 145123529.74018514, 137323072.0347904]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.19193e+08\n",
      "[400]\tvalid_0's l2: 1.16099e+08\n",
      "[600]\tvalid_0's l2: 1.13811e+08\n",
      "[800]\tvalid_0's l2: 1.11634e+08\n",
      "[1000]\tvalid_0's l2: 1.11014e+08\n",
      "Early stopping, best iteration is:\n",
      "[904]\tvalid_0's l2: 1.10266e+08\n",
      "cv_score is: [110940659.75047639, 106513195.56387173, 138052331.11609027, 110078380.21866015, 145123529.74018514, 137323072.0347904, 110265801.06856759]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 8.49659e+07\n",
      "[400]\tvalid_0's l2: 7.0456e+07\n",
      "[600]\tvalid_0's l2: 6.75455e+07\n",
      "[800]\tvalid_0's l2: 6.74996e+07\n",
      "Early stopping, best iteration is:\n",
      "[653]\tvalid_0's l2: 6.6799e+07\n",
      "cv_score is: [110940659.75047639, 106513195.56387173, 138052331.11609027, 110078380.21866015, 145123529.74018514, 137323072.0347904, 110265801.06856759, 66798971.13433192]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.70238e+08\n",
      "[400]\tvalid_0's l2: 1.54432e+08\n",
      "[600]\tvalid_0's l2: 1.48826e+08\n",
      "[800]\tvalid_0's l2: 1.47655e+08\n",
      "Early stopping, best iteration is:\n",
      "[717]\tvalid_0's l2: 1.47287e+08\n",
      "cv_score is: [110940659.75047639, 106513195.56387173, 138052331.11609027, 110078380.21866015, 145123529.74018514, 137323072.0347904, 110265801.06856759, 66798971.13433192, 147287034.57403302]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.52183e+08\n",
      "[400]\tvalid_0's l2: 1.46907e+08\n",
      "[600]\tvalid_0's l2: 1.42445e+08\n",
      "[800]\tvalid_0's l2: 1.40165e+08\n",
      "[1000]\tvalid_0's l2: 1.39357e+08\n",
      "[1200]\tvalid_0's l2: 1.37736e+08\n",
      "[1400]\tvalid_0's l2: 1.36525e+08\n",
      "[1600]\tvalid_0's l2: 1.35293e+08\n",
      "[1800]\tvalid_0's l2: 1.34878e+08\n",
      "Early stopping, best iteration is:\n",
      "[1761]\tvalid_0's l2: 1.34694e+08\n",
      "cv_score is: [110940659.75047639, 106513195.56387173, 138052331.11609027, 110078380.21866015, 145123529.74018514, 137323072.0347904, 110265801.06856759, 66798971.13433192, 147287034.57403302, 134693731.6757458]\n",
      "val_mean: 120707670.68767524\n",
      "val_std: 23452410.19251036\n",
      "A厂的验证集mape为0.006748706322373056\n",
      "(550, 8) (550,) (151, 8)\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 4.83495e+07\n",
      "[400]\tvalid_0's l2: 4.03753e+07\n",
      "[600]\tvalid_0's l2: 4.03588e+07\n",
      "Early stopping, best iteration is:\n",
      "[518]\tvalid_0's l2: 3.95676e+07\n",
      "cv_score is: [39567640.3188509]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.90659e+08\n",
      "[400]\tvalid_0's l2: 1.70233e+08\n",
      "[600]\tvalid_0's l2: 1.61659e+08\n",
      "[800]\tvalid_0's l2: 1.5725e+08\n",
      "[1000]\tvalid_0's l2: 1.55479e+08\n",
      "[1200]\tvalid_0's l2: 1.54571e+08\n",
      "[1400]\tvalid_0's l2: 1.5392e+08\n",
      "[1600]\tvalid_0's l2: 1.53649e+08\n",
      "[1800]\tvalid_0's l2: 1.53242e+08\n",
      "[2000]\tvalid_0's l2: 1.52922e+08\n",
      "[2200]\tvalid_0's l2: 1.52679e+08\n",
      "[2400]\tvalid_0's l2: 1.52561e+08\n",
      "Early stopping, best iteration is:\n",
      "[2271]\tvalid_0's l2: 1.52396e+08\n",
      "cv_score is: [39567640.3188509, 152396315.07154322]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 1.05738e+08\n",
      "[400]\tvalid_0's l2: 7.11691e+07\n",
      "[600]\tvalid_0's l2: 5.98482e+07\n",
      "[800]\tvalid_0's l2: 5.41054e+07\n",
      "[1000]\tvalid_0's l2: 5.1809e+07\n",
      "[1200]\tvalid_0's l2: 5.04618e+07\n",
      "[1400]\tvalid_0's l2: 4.98765e+07\n",
      "[1600]\tvalid_0's l2: 4.91151e+07\n",
      "[1800]\tvalid_0's l2: 4.8705e+07\n",
      "[2000]\tvalid_0's l2: 4.8385e+07\n",
      "[2200]\tvalid_0's l2: 4.82069e+07\n",
      "[2400]\tvalid_0's l2: 4.81417e+07\n",
      "[2600]\tvalid_0's l2: 4.78961e+07\n",
      "[2800]\tvalid_0's l2: 4.76833e+07\n",
      "[3000]\tvalid_0's l2: 4.75031e+07\n",
      "[3200]\tvalid_0's l2: 4.73489e+07\n",
      "[3400]\tvalid_0's l2: 4.73516e+07\n",
      "[3600]\tvalid_0's l2: 4.71979e+07\n",
      "[3800]\tvalid_0's l2: 4.71489e+07\n",
      "[4000]\tvalid_0's l2: 4.71344e+07\n",
      "[4200]\tvalid_0's l2: 4.70869e+07\n",
      "[4400]\tvalid_0's l2: 4.70742e+07\n",
      "[4600]\tvalid_0's l2: 4.70362e+07\n",
      "[4800]\tvalid_0's l2: 4.69881e+07\n",
      "Early stopping, best iteration is:\n",
      "[4799]\tvalid_0's l2: 4.69851e+07\n",
      "cv_score is: [39567640.3188509, 152396315.07154322, 46985117.20279528]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 5.25589e+07\n",
      "[400]\tvalid_0's l2: 4.86866e+07\n",
      "[600]\tvalid_0's l2: 4.853e+07\n",
      "Early stopping, best iteration is:\n",
      "[448]\tvalid_0's l2: 4.80764e+07\n",
      "cv_score is: [39567640.3188509, 152396315.07154322, 46985117.20279528, 48076370.16902754]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 2.00525e+08\n",
      "[400]\tvalid_0's l2: 1.86784e+08\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's l2: 1.85085e+08\n",
      "cv_score is: [39567640.3188509, 152396315.07154322, 46985117.20279528, 48076370.16902754, 185085063.29742968]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 9.75542e+07\n",
      "[400]\tvalid_0's l2: 7.64641e+07\n",
      "[600]\tvalid_0's l2: 6.8464e+07\n",
      "[800]\tvalid_0's l2: 6.45872e+07\n",
      "[1000]\tvalid_0's l2: 6.18831e+07\n",
      "[1200]\tvalid_0's l2: 5.96757e+07\n",
      "[1400]\tvalid_0's l2: 5.7951e+07\n",
      "[1600]\tvalid_0's l2: 5.6858e+07\n",
      "[1800]\tvalid_0's l2: 5.602e+07\n",
      "[2000]\tvalid_0's l2: 5.54084e+07\n",
      "[2200]\tvalid_0's l2: 5.49044e+07\n",
      "[2400]\tvalid_0's l2: 5.46502e+07\n",
      "[2600]\tvalid_0's l2: 5.43162e+07\n",
      "[2800]\tvalid_0's l2: 5.40321e+07\n",
      "[3000]\tvalid_0's l2: 5.38169e+07\n",
      "[3200]\tvalid_0's l2: 5.35845e+07\n",
      "[3400]\tvalid_0's l2: 5.34234e+07\n",
      "[3600]\tvalid_0's l2: 5.32879e+07\n",
      "[3800]\tvalid_0's l2: 5.31419e+07\n",
      "[4000]\tvalid_0's l2: 5.29982e+07\n",
      "[4200]\tvalid_0's l2: 5.28412e+07\n",
      "[4400]\tvalid_0's l2: 5.27893e+07\n",
      "Early stopping, best iteration is:\n",
      "[4258]\tvalid_0's l2: 5.27825e+07\n",
      "cv_score is: [39567640.3188509, 152396315.07154322, 46985117.20279528, 48076370.16902754, 185085063.29742968, 52782529.678257644]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 6.77503e+07\n",
      "[400]\tvalid_0's l2: 5.8151e+07\n",
      "[600]\tvalid_0's l2: 5.46726e+07\n",
      "[800]\tvalid_0's l2: 5.35734e+07\n",
      "[1000]\tvalid_0's l2: 5.28992e+07\n",
      "[1200]\tvalid_0's l2: 5.23712e+07\n",
      "[1400]\tvalid_0's l2: 5.22366e+07\n",
      "Early stopping, best iteration is:\n",
      "[1398]\tvalid_0's l2: 5.21932e+07\n",
      "cv_score is: [39567640.3188509, 152396315.07154322, 46985117.20279528, 48076370.16902754, 185085063.29742968, 52782529.678257644, 52193153.23436018]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 3.43726e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's l2: 3.42939e+07\n",
      "cv_score is: [39567640.3188509, 152396315.07154322, 46985117.20279528, 48076370.16902754, 185085063.29742968, 52782529.678257644, 52193153.23436018, 34293873.57084108]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 6.26995e+07\n",
      "[400]\tvalid_0's l2: 5.43561e+07\n",
      "[600]\tvalid_0's l2: 5.36191e+07\n",
      "Early stopping, best iteration is:\n",
      "[498]\tvalid_0's l2: 5.34072e+07\n",
      "cv_score is: [39567640.3188509, 152396315.07154322, 46985117.20279528, 48076370.16902754, 185085063.29742968, 52782529.678257644, 52193153.23436018, 34293873.57084108, 53407210.23511568]\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid_0's l2: 6.99081e+07\n",
      "[400]\tvalid_0's l2: 6.21119e+07\n",
      "[600]\tvalid_0's l2: 6.14074e+07\n",
      "[800]\tvalid_0's l2: 6.12763e+07\n",
      "Early stopping, best iteration is:\n",
      "[616]\tvalid_0's l2: 6.11721e+07\n",
      "cv_score is: [39567640.3188509, 152396315.07154322, 46985117.20279528, 48076370.16902754, 185085063.29742968, 52782529.678257644, 52193153.23436018, 34293873.57084108, 53407210.23511568, 61172057.36491623]\n",
      "val_mean: 72595933.01431373\n",
      "val_std: 49137053.76213749\n",
      "B厂的验证集mape为0.006538176240147742\n",
      "218812.35963940763 33040666.305550553 170791.56248937335 25789525.935895376\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "\n",
    "    select_frts=['day_of_year', 'day_of_month', 'week_of_year',\n",
    "            'week_of_year', 'week_block_num', 'CH_day_of_month',\n",
    "            'CH_day_of_year', 'abs_year', ]    #burata特征选择结果\n",
    "\n",
    "    train_df=train_day_df_A#训练集A\n",
    "    \n",
    "    \n",
    "    train_df=train_df[((train_df['date']>='2019-05-01'))].reset_index(drop=True)\n",
    "    test_df=test_day_df_A#测试集A\n",
    "    train_x = train_df[select_frts].copy()\n",
    "    train_y = train_df['A']\n",
    "    test_x = test_df[select_frts].copy()\n",
    "    print(train_x.shape,train_y.shape,test_x.shape)\n",
    "    model,lgb_train, lgb_test, sb, cv_scores, importance_list = lgb_cv(train_x, train_y, test_x)\n",
    "    lgb_test_A=[item if item>0 else 0 for item in lgb_test]\n",
    "    val_A_pre = model.predict(train_x[-30:])\n",
    "    print(f\"A厂的验证集mape为{mape(val_A_pre, train_y[-30:])}\")\n",
    "    \n",
    "    \n",
    "    train_df=train_day_df_B#训练集B\n",
    "    train_df=train_df[((train_df['date']>='2019-05-01'))].reset_index(drop=True)\n",
    " \n",
    "    \n",
    "\n",
    "    test_df=test_day_df_B#测试集B\n",
    "    train_x = train_df[select_frts].copy()\n",
    "    train_y = train_df['B']\n",
    "    test_x = test_df[select_frts].copy()\n",
    "    print(train_x.shape,train_y.shape,test_x.shape)\n",
    "    model,lgb_train, lgb_test, sb, cv_scores, importance_list = lgb_cv(train_x, train_y, test_x)\n",
    "    \n",
    "    val_B_pre = model.predict(train_x[-30:])\n",
    "    print(f\"B厂的验证集mape为{mape(val_B_pre, train_y[-30:])}\")    \n",
    "    \n",
    "    lgb_test_B=[item if item>0 else 0 for item in lgb_test]\n",
    "    print(np.mean(lgb_test_A),np.sum(lgb_test_A),np.mean(lgb_test_B),np.sum(lgb_test_B))\n",
    "    pre_A=np.array(lgb_test_A)\n",
    "    pre_B=np.array(lgb_test_B)\n",
    "    \n",
    "    pre_day_A=[]\n",
    "    pre_day_B=[]\n",
    "    for i in range(151):\n",
    "        pre_day_A.append(pre_A[i])\n",
    "        pre_day_B.append(pre_B[i])\n",
    "    test_day['A']=pre_day_A\n",
    "    test_day['B']=pre_day_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A厂的验证集mape为0.006748706322373056\n",
    "B厂的验证集mape为0.006538176240147742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_day['A'] = test_day['A'].astype(int)\n",
    "test_day['B'] = test_day['B'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日期</th>\n",
       "      <th>A厂</th>\n",
       "      <th>B厂</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020/11/01</td>\n",
       "      <td>262634</td>\n",
       "      <td>227376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020/11/02</td>\n",
       "      <td>264562</td>\n",
       "      <td>229334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020/11/03</td>\n",
       "      <td>265148</td>\n",
       "      <td>230754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020/11/04</td>\n",
       "      <td>259702</td>\n",
       "      <td>236091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020/11/05</td>\n",
       "      <td>258913</td>\n",
       "      <td>235196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2021/03/27</td>\n",
       "      <td>220933</td>\n",
       "      <td>163203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2021/03/28</td>\n",
       "      <td>219865</td>\n",
       "      <td>161103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2021/03/29</td>\n",
       "      <td>219443</td>\n",
       "      <td>162642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2021/03/30</td>\n",
       "      <td>217775</td>\n",
       "      <td>162795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2021/03/31</td>\n",
       "      <td>218865</td>\n",
       "      <td>163224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             日期      A厂      B厂\n",
       "0    2020/11/01  262634  227376\n",
       "1    2020/11/02  264562  229334\n",
       "2    2020/11/03  265148  230754\n",
       "3    2020/11/04  259702  236091\n",
       "4    2020/11/05  258913  235196\n",
       "..          ...     ...     ...\n",
       "146  2021/03/27  220933  163203\n",
       "147  2021/03/28  219865  161103\n",
       "148  2021/03/29  219443  162642\n",
       "149  2021/03/30  217775  162795\n",
       "150  2021/03/31  218865  163224\n",
       "\n",
       "[151 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_v11 = pd.read_csv('../data/test.csv')\n",
    "test_v11['A厂'] = test_day['A']\n",
    "test_v11['B厂'] = test_day['B']\n",
    "test_v11.to_csv('./data/lgb_kfold_play_.csv',index=False,encoding = 'utf-8')   #存储原始结果\n",
    "test_v11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>262634</td>\n",
       "      <td>227376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>264562</td>\n",
       "      <td>229334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>265148</td>\n",
       "      <td>230754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>259702</td>\n",
       "      <td>236091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>258913</td>\n",
       "      <td>235196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2021-03-27</td>\n",
       "      <td>220933</td>\n",
       "      <td>163203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2021-03-28</td>\n",
       "      <td>219865</td>\n",
       "      <td>161103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>219443</td>\n",
       "      <td>162642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>217775</td>\n",
       "      <td>162795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>218865</td>\n",
       "      <td>163224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date       A       B\n",
       "0   2020-11-01  262634  227376\n",
       "1   2020-11-02  264562  229334\n",
       "2   2020-11-03  265148  230754\n",
       "3   2020-11-04  259702  236091\n",
       "4   2020-11-05  258913  235196\n",
       "..         ...     ...     ...\n",
       "146 2021-03-27  220933  163203\n",
       "147 2021-03-28  219865  161103\n",
       "148 2021-03-29  219443  162642\n",
       "149 2021-03-30  217775  162795\n",
       "150 2021-03-31  218865  163224\n",
       "\n",
       "[151 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_day[['date','A','B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "excel操作后读取规则2021年结果，规则细节在total_submit文件中有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020/11/1</td>\n",
       "      <td>272186.00</td>\n",
       "      <td>236361.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020/11/2</td>\n",
       "      <td>266976.00</td>\n",
       "      <td>243226.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020/11/3</td>\n",
       "      <td>268541.00</td>\n",
       "      <td>240503.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020/11/4</td>\n",
       "      <td>266992.00</td>\n",
       "      <td>236450.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020/11/5</td>\n",
       "      <td>267706.00</td>\n",
       "      <td>238724.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2021/3/27</td>\n",
       "      <td>270559.81</td>\n",
       "      <td>254224.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2021/3/28</td>\n",
       "      <td>269251.86</td>\n",
       "      <td>255687.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2021/3/29</td>\n",
       "      <td>275184.60</td>\n",
       "      <td>258130.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2021/3/30</td>\n",
       "      <td>275226.01</td>\n",
       "      <td>258373.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2021/3/31</td>\n",
       "      <td>276602.64</td>\n",
       "      <td>259053.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date          A          B\n",
       "0    2020/11/1  272186.00  236361.00\n",
       "1    2020/11/2  266976.00  243226.00\n",
       "2    2020/11/3  268541.00  240503.00\n",
       "3    2020/11/4  266992.00  236450.00\n",
       "4    2020/11/5  267706.00  238724.00\n",
       "..         ...        ...        ...\n",
       "146  2021/3/27  270559.81  254224.07\n",
       "147  2021/3/28  269251.86  255687.56\n",
       "148  2021/3/29  275184.60  258130.75\n",
       "149  2021/3/30  275226.01  258373.15\n",
       "150  2021/3/31  276602.64  259053.89\n",
       "\n",
       "[151 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('./data/lgb_fold_play__2021_970_20212_101.csv')   \n",
    "df1.columns=['date','A','B']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日期</th>\n",
       "      <th>A厂</th>\n",
       "      <th>B厂</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020/11/01</td>\n",
       "      <td>272186</td>\n",
       "      <td>236361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020/11/02</td>\n",
       "      <td>266976</td>\n",
       "      <td>243226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020/11/03</td>\n",
       "      <td>268541</td>\n",
       "      <td>240503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020/11/04</td>\n",
       "      <td>266992</td>\n",
       "      <td>236450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020/11/05</td>\n",
       "      <td>267706</td>\n",
       "      <td>238724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2021/03/27</td>\n",
       "      <td>270559</td>\n",
       "      <td>254224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2021/03/28</td>\n",
       "      <td>269251</td>\n",
       "      <td>255687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2021/03/29</td>\n",
       "      <td>275184</td>\n",
       "      <td>258130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2021/03/30</td>\n",
       "      <td>275226</td>\n",
       "      <td>258373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2021/03/31</td>\n",
       "      <td>276602</td>\n",
       "      <td>259053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             日期      A厂      B厂\n",
       "0    2020/11/01  272186  236361\n",
       "1    2020/11/02  266976  243226\n",
       "2    2020/11/03  268541  240503\n",
       "3    2020/11/04  266992  236450\n",
       "4    2020/11/05  267706  238724\n",
       "..          ...     ...     ...\n",
       "146  2021/03/27  270559  254224\n",
       "147  2021/03/28  269251  255687\n",
       "148  2021/03/29  275184  258130\n",
       "149  2021/03/30  275226  258373\n",
       "150  2021/03/31  276602  259053\n",
       "\n",
       "[151 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_v11 = pd.read_csv('../data/test.csv')\n",
    "test_v11['A厂'] = df1.A.astype(int)\n",
    "test_v11['B厂'] = df1.B.astype(int)\n",
    "test_v11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v11.to_csv('./data/lgb_fold_play__2021_970_20212_101.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
